{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 1000,
  "global_step": 924,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06493506493506493,
      "grad_norm": 3.639680404256587,
      "learning_rate": 4.255319148936171e-06,
      "loss": 0.4607,
      "step": 20
    },
    {
      "epoch": 0.12987012987012986,
      "grad_norm": 1.0017952301956712,
      "learning_rate": 8.510638297872341e-06,
      "loss": 0.0663,
      "step": 40
    },
    {
      "epoch": 0.19480519480519481,
      "grad_norm": 0.8794512944856048,
      "learning_rate": 9.994579382225176e-06,
      "loss": 0.032,
      "step": 60
    },
    {
      "epoch": 0.2597402597402597,
      "grad_norm": 0.4987627457063294,
      "learning_rate": 9.965105044945138e-06,
      "loss": 0.0296,
      "step": 80
    },
    {
      "epoch": 0.3246753246753247,
      "grad_norm": 0.38450125504823385,
      "learning_rate": 9.910156351396135e-06,
      "loss": 0.0268,
      "step": 100
    },
    {
      "epoch": 0.38961038961038963,
      "grad_norm": 0.50154251344022,
      "learning_rate": 9.830015225642872e-06,
      "loss": 0.026,
      "step": 120
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 0.5568434228731827,
      "learning_rate": 9.725092846013053e-06,
      "loss": 0.024,
      "step": 140
    },
    {
      "epoch": 0.5194805194805194,
      "grad_norm": 0.3236713729475153,
      "learning_rate": 9.59592753547368e-06,
      "loss": 0.0239,
      "step": 160
    },
    {
      "epoch": 0.5844155844155844,
      "grad_norm": 0.4575942394772656,
      "learning_rate": 9.443181999669143e-06,
      "loss": 0.0231,
      "step": 180
    },
    {
      "epoch": 0.6493506493506493,
      "grad_norm": 0.6180846056260535,
      "learning_rate": 9.267639926791805e-06,
      "loss": 0.0242,
      "step": 200
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.7487351162279746,
      "learning_rate": 9.07020196673008e-06,
      "loss": 0.0242,
      "step": 220
    },
    {
      "epoch": 0.7792207792207793,
      "grad_norm": 0.6195435040525988,
      "learning_rate": 8.851881110123657e-06,
      "loss": 0.0233,
      "step": 240
    },
    {
      "epoch": 0.8441558441558441,
      "grad_norm": 0.47221836582491594,
      "learning_rate": 8.613797491034519e-06,
      "loss": 0.0227,
      "step": 260
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.5364923991031949,
      "learning_rate": 8.357172639899497e-06,
      "loss": 0.0217,
      "step": 280
    },
    {
      "epoch": 0.974025974025974,
      "grad_norm": 0.3489440469047359,
      "learning_rate": 8.083323216250688e-06,
      "loss": 0.0205,
      "step": 300
    },
    {
      "epoch": 1.0389610389610389,
      "grad_norm": 0.3616720470161571,
      "learning_rate": 7.793654253359075e-06,
      "loss": 0.0207,
      "step": 320
    },
    {
      "epoch": 1.103896103896104,
      "grad_norm": 0.3456844712736636,
      "learning_rate": 7.489651949460946e-06,
      "loss": 0.0191,
      "step": 340
    },
    {
      "epoch": 1.1688311688311688,
      "grad_norm": 0.3880479491656531,
      "learning_rate": 7.172876042552974e-06,
      "loss": 0.0191,
      "step": 360
    },
    {
      "epoch": 1.2337662337662338,
      "grad_norm": 0.3487136170164777,
      "learning_rate": 6.8449518078784705e-06,
      "loss": 0.0203,
      "step": 380
    },
    {
      "epoch": 1.2987012987012987,
      "grad_norm": 0.3715035434594982,
      "learning_rate": 6.507561719163111e-06,
      "loss": 0.0184,
      "step": 400
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 0.6042367768440787,
      "learning_rate": 6.162436816383646e-06,
      "loss": 0.0191,
      "step": 420
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.4294300695361364,
      "learning_rate": 5.811347824358802e-06,
      "loss": 0.0185,
      "step": 440
    },
    {
      "epoch": 1.4935064935064934,
      "grad_norm": 0.4119132239530809,
      "learning_rate": 5.456096067730055e-06,
      "loss": 0.0179,
      "step": 460
    },
    {
      "epoch": 1.5584415584415585,
      "grad_norm": 0.3245585166485438,
      "learning_rate": 5.098504228944522e-06,
      "loss": 0.0177,
      "step": 480
    },
    {
      "epoch": 1.6233766233766234,
      "grad_norm": 0.44620035571221367,
      "learning_rate": 4.740406996657863e-06,
      "loss": 0.0175,
      "step": 500
    },
    {
      "epoch": 1.6883116883116882,
      "grad_norm": 0.3503458268734623,
      "learning_rate": 4.383641652537155e-06,
      "loss": 0.0162,
      "step": 520
    },
    {
      "epoch": 1.7532467532467533,
      "grad_norm": 0.3884779671652721,
      "learning_rate": 4.030038644759886e-06,
      "loss": 0.0174,
      "step": 540
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 0.32203902167169635,
      "learning_rate": 3.6814121965733695e-06,
      "loss": 0.0174,
      "step": 560
    },
    {
      "epoch": 1.883116883116883,
      "grad_norm": 0.38340921022474256,
      "learning_rate": 3.339550998099063e-06,
      "loss": 0.0176,
      "step": 580
    },
    {
      "epoch": 1.948051948051948,
      "grad_norm": 0.31589414810394983,
      "learning_rate": 3.0062090291391325e-06,
      "loss": 0.0162,
      "step": 600
    },
    {
      "epoch": 2.012987012987013,
      "grad_norm": 0.3215769373782515,
      "learning_rate": 2.6830965600704994e-06,
      "loss": 0.0175,
      "step": 620
    },
    {
      "epoch": 2.0779220779220777,
      "grad_norm": 0.40772778153593137,
      "learning_rate": 2.3718713769978925e-06,
      "loss": 0.0152,
      "step": 640
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 0.31166469277345016,
      "learning_rate": 2.0741302761867838e-06,
      "loss": 0.0144,
      "step": 660
    },
    {
      "epoch": 2.207792207792208,
      "grad_norm": 0.34456922706750465,
      "learning_rate": 1.7914008714155984e-06,
      "loss": 0.0143,
      "step": 680
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 0.40504366324379065,
      "learning_rate": 1.525133756280977e-06,
      "loss": 0.0146,
      "step": 700
    },
    {
      "epoch": 2.3376623376623376,
      "grad_norm": 0.4202581434306193,
      "learning_rate": 1.2766950616688233e-06,
      "loss": 0.0153,
      "step": 720
    },
    {
      "epoch": 2.4025974025974026,
      "grad_norm": 0.344965670819574,
      "learning_rate": 1.0473594465763282e-06,
      "loss": 0.0137,
      "step": 740
    },
    {
      "epoch": 2.4675324675324677,
      "grad_norm": 0.3157194005843755,
      "learning_rate": 8.383035582468341e-07,
      "loss": 0.0146,
      "step": 760
    },
    {
      "epoch": 2.5324675324675323,
      "grad_norm": 0.31916243246364107,
      "learning_rate": 6.505999951714537e-07,
      "loss": 0.0153,
      "step": 780
    },
    {
      "epoch": 2.5974025974025974,
      "grad_norm": 0.36591400315370803,
      "learning_rate": 4.852118039313691e-07,
      "loss": 0.0147,
      "step": 800
    },
    {
      "epoch": 2.6623376623376624,
      "grad_norm": 0.3384219385833307,
      "learning_rate": 3.429875381157161e-07,
      "loss": 0.0152,
      "step": 820
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 0.3249989280316207,
      "learning_rate": 2.246569046661773e-07,
      "loss": 0.0151,
      "step": 840
    },
    {
      "epoch": 2.792207792207792,
      "grad_norm": 0.38994776192521874,
      "learning_rate": 1.3082701998547498e-07,
      "loss": 0.0142,
      "step": 860
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.32522209446685546,
      "learning_rate": 6.197929501847277e-08,
      "loss": 0.0144,
      "step": 880
    },
    {
      "epoch": 2.9220779220779223,
      "grad_norm": 0.3192223629814701,
      "learning_rate": 1.846696528752967e-08,
      "loss": 0.0143,
      "step": 900
    },
    {
      "epoch": 2.987012987012987,
      "grad_norm": 0.2961448298256253,
      "learning_rate": 5.132785547018459e-10,
      "loss": 0.0139,
      "step": 920
    }
  ],
  "logging_steps": 20,
  "max_steps": 924,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.008388464954573e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
